commit 988e09f27b9b04a43d45d10f92782e0092ee27a9
Author: Jia Tan <jiat0218@gmail.com>
Date:   Fri Oct 20 19:17:46 2023 +0800

    liblzma: Move is_clmul_supported() back to crc_common.h.
    
    This partially reverts creating crc_clmul.c
    (8c0f9376f58c0696d5d6719705164d35542dd891) where is_clmul_supported()
    was moved, extern'ed, and renamed to lzma_is_clmul_supported(). This
    caused a problem when the function call to lzma_is_clmul_supported()
    results in a call through the PLT. ifunc resolvers run very early in
    the dynamic loading sequence, so the PLT may not be setup properly at
    this point. Whether the PLT is used or not for
    lzma_is_clmul_supported() depened upon the compiler-toolchain used and
    flags.
    
    In liblzma compiled with GCC, for instance, GCC will go through the PLT
    for function calls internal to liblzma if the version scripts and
    symbol visibility hiding are not used. If lazy-binding is disabled,
    then it would have made any program linked with liblzma fail during
    dynamic loading in the ifunc resolver.

diff --git a/src/liblzma/check/crc32_fast.c b/src/liblzma/check/crc32_fast.c
index add93d55..73659049 100644
--- a/src/liblzma/check/crc32_fast.c
+++ b/src/liblzma/check/crc32_fast.c
@@ -1,228 +1,228 @@
 ///////////////////////////////////////////////////////////////////////////////
 //
 /// \file       crc32.c
 /// \brief      CRC32 calculation
 //
 //  Authors:    Lasse Collin
 //              Ilya Kurdyukov
 //              Hans Jansen
 //
 //  This file has been put into the public domain.
 //  You can do whatever you want with this file.
 //
 ///////////////////////////////////////////////////////////////////////////////
 
 #include "check.h"
 #include "crc_common.h"
 
 #ifdef CRC_GENERIC
 
 ///////////////////
 // Generic CRC32 //
 ///////////////////
 
 static uint32_t
 crc32_generic(const uint8_t *buf, size_t size, uint32_t crc)
 {
 	crc = ~crc;
 
 #ifdef WORDS_BIGENDIAN
 	crc = bswap32(crc);
 #endif
 
 	if (size > 8) {
 		// Fix the alignment, if needed. The if statement above
 		// ensures that this won't read past the end of buf[].
 		while ((uintptr_t)(buf) & 7) {
 			crc = lzma_crc32_table[0][*buf++ ^ A(crc)] ^ S8(crc);
 			--size;
 		}
 
 		// Calculate the position where to stop.
 		const uint8_t *const limit = buf + (size & ~(size_t)(7));
 
 		// Calculate how many bytes must be calculated separately
 		// before returning the result.
 		size &= (size_t)(7);
 
 		// Calculate the CRC32 using the slice-by-eight algorithm.
 		while (buf < limit) {
 			crc ^= aligned_read32ne(buf);
 			buf += 4;
 
 			crc = lzma_crc32_table[7][A(crc)]
 			    ^ lzma_crc32_table[6][B(crc)]
 			    ^ lzma_crc32_table[5][C(crc)]
 			    ^ lzma_crc32_table[4][D(crc)];
 
 			const uint32_t tmp = aligned_read32ne(buf);
 			buf += 4;
 
 			// At least with some compilers, it is critical for
 			// performance, that the crc variable is XORed
 			// between the two table-lookup pairs.
 			crc = lzma_crc32_table[3][A(tmp)]
 			    ^ lzma_crc32_table[2][B(tmp)]
 			    ^ crc
 			    ^ lzma_crc32_table[1][C(tmp)]
 			    ^ lzma_crc32_table[0][D(tmp)];
 		}
 	}
 
 	while (size-- != 0)
 		crc = lzma_crc32_table[0][*buf++ ^ A(crc)] ^ S8(crc);
 
 #ifdef WORDS_BIGENDIAN
 	crc = bswap32(crc);
 #endif
 
 	return ~crc;
 }
 #endif
 
 #if defined(CRC_GENERIC) && defined(CRC_CLMUL)
 
 //////////////////////////
 // Function dispatching //
 //////////////////////////
 
 // If both the generic and CLMUL implementations are built, then the
 // function to use is selected at runtime since system running the
 // binary may not have the CLMUL instructions.
 // The three dispatch methods in order of priority:
 //
 // 1. Indirect function (ifunc). This method is slightly more efficient
 //    than the constructor method because it will change the entry in the
 //    Procedure Linkage Table (PLT) for the function either at load time or
 //    at the first call. This avoids having to call the function through a
 //    function pointer and will treat the function call like a regular call
 //    through the PLT. ifuncs are created by using
 //    __attribute__((__ifunc__("resolver"))) on a function which has no
 //    body. The "resolver" is the name of the function that chooses at
 //    runtime which implementation to use.
 //
 // 2. Constructor. This method uses __attribute__((__constructor__)) to
 //    set crc32_func at load time. This avoids extra computation (and any
 //    unlikely threading bugs) on the first call to lzma_crc32() to decide
 //    which implementation should be used.
 //
 // 3. First Call Resolution. On the very first call to lzma_crc32(), the
 //    call will be directed to crc32_dispatch() instead. This will set the
 //    appropriate implementation function and will not be called again.
 //    This method does not use any kind of locking but is safe because if
 //    multiple threads run the dispatcher simultaneously then they will all
 //    set crc32_func to the same value.
 
 typedef uint32_t (*crc32_func_type)(
 		const uint8_t *buf, size_t size, uint32_t crc);
 
 // Clang 16.0.0 and older has a bug where it marks the ifunc resolver
 // function as unused since it is static and never used outside of
 // __attribute__((__ifunc__())).
 #if defined(HAVE_FUNC_ATTRIBUTE_IFUNC) && defined(__clang__)
 #	pragma GCC diagnostic push
 #	pragma GCC diagnostic ignored "-Wunused-function"
 #endif
 
 // This resolver is shared between all three dispatch methods. It serves as
 // the ifunc resolver if ifunc is supported, otherwise it is called as a
 // regular function by the constructor or first call resolution methods.
 static crc32_func_type
 crc32_resolve(void)
 {
-	return lzma_is_clmul_supported() ? &lzma_crc32_clmul : &crc32_generic;
+	return is_clmul_supported() ? &lzma_crc32_clmul : &crc32_generic;
 }
 
 #if defined(HAVE_FUNC_ATTRIBUTE_IFUNC) && defined(__clang__)
 #	pragma GCC diagnostic pop
 #endif
 
 #ifndef HAVE_FUNC_ATTRIBUTE_IFUNC
 
 #ifdef HAVE_FUNC_ATTRIBUTE_CONSTRUCTOR
 // Constructor method.
 #	define CRC32_SET_FUNC_ATTR __attribute__((__constructor__))
 static crc32_func_type crc32_func;
 #else
 // First Call Resolution method.
 #	define CRC32_SET_FUNC_ATTR
 static uint32_t crc32_dispatch(const uint8_t *buf, size_t size, uint32_t crc);
 static crc32_func_type crc32_func = &crc32_dispatch;
 #endif
 
 CRC32_SET_FUNC_ATTR
 static void
 crc32_set_func(void)
 {
 	crc32_func = crc32_resolve();
 	return;
 }
 
 #ifndef HAVE_FUNC_ATTRIBUTE_CONSTRUCTOR
 static uint32_t
 crc32_dispatch(const uint8_t *buf, size_t size, uint32_t crc)
 {
 	// When __attribute__((__ifunc__(...))) and
 	// __attribute__((__constructor__)) isn't supported, set the
 	// function pointer without any locking. If multiple threads run
 	// the detection code in parallel, they will all end up setting
 	// the pointer to the same value. This avoids the use of
 	// mythread_once() on every call to lzma_crc32() but this likely
 	// isn't strictly standards compliant. Let's change it if it breaks.
 	crc32_set_func();
 	return crc32_func(buf, size, crc);
 }
 
 #endif
 #endif
 #endif
 
 
 #ifdef CRC_USE_IFUNC
 extern LZMA_API(uint32_t)
 lzma_crc32(const uint8_t *buf, size_t size, uint32_t crc)
 		__attribute__((__ifunc__("crc32_resolve")));
 #else
 extern LZMA_API(uint32_t)
 lzma_crc32(const uint8_t *buf, size_t size, uint32_t crc)
 {
 #if defined(CRC_GENERIC) && defined(CRC_CLMUL)
 	// If CLMUL is available, it is the best for non-tiny inputs,
 	// being over twice as fast as the generic slice-by-four version.
 	// However, for size <= 16 it's different. In the extreme case
 	// of size == 1 the generic version can be five times faster.
 	// At size >= 8 the CLMUL starts to become reasonable. It
 	// varies depending on the alignment of buf too.
 	//
 	// The above doesn't include the overhead of mythread_once().
 	// At least on x86-64 GNU/Linux, pthread_once() is very fast but
 	// it still makes lzma_crc32(buf, 1, crc) 50-100 % slower. When
 	// size reaches 12-16 bytes the overhead becomes negligible.
 	//
 	// So using the generic version for size <= 16 may give better
 	// performance with tiny inputs but if such inputs happen rarely
 	// it's not so obvious because then the lookup table of the
 	// generic version may not be in the processor cache.
 #ifdef CRC_USE_GENERIC_FOR_SMALL_INPUTS
 	if (size <= 16)
 		return crc32_generic(buf, size, crc);
 #endif
 
 /*
 #ifndef HAVE_FUNC_ATTRIBUTE_CONSTRUCTOR
 	// See crc32_dispatch(). This would be the alternative which uses
 	// locking and doesn't use crc32_dispatch(). Note that on Windows
 	// this method needs Vista threads.
 	mythread_once(crc64_set_func);
 #endif
 */
 	return crc32_func(buf, size, crc);
 
 #elif defined(CRC_CLMUL)
 	return lzma_crc32_clmul(buf, size, crc);
 
 #else
 	return crc32_generic(buf, size, crc);
 #endif
 }
 #endif
diff --git a/src/liblzma/check/crc64_fast.c b/src/liblzma/check/crc64_fast.c
index 8acdc713..4e6633db 100644
--- a/src/liblzma/check/crc64_fast.c
+++ b/src/liblzma/check/crc64_fast.c
@@ -1,166 +1,166 @@
 ///////////////////////////////////////////////////////////////////////////////
 //
 /// \file       crc64.c
 /// \brief      CRC64 calculation
 //
 //  Authors:    Lasse Collin
 //              Ilya Kurdyukov
 //
 //  This file has been put into the public domain.
 //  You can do whatever you want with this file.
 //
 ///////////////////////////////////////////////////////////////////////////////
 
 #include "check.h"
 #include "crc_common.h"
 
 #ifdef CRC_GENERIC
 
 /////////////////////////////////
 // Generic slice-by-four CRC64 //
 /////////////////////////////////
 
 #ifdef WORDS_BIGENDIAN
 #	define A1(x) ((x) >> 56)
 #else
 #	define A1 A
 #endif
 
 
 // See the comments in crc32_fast.c. They aren't duplicated here.
 static uint64_t
 crc64_generic(const uint8_t *buf, size_t size, uint64_t crc)
 {
 	crc = ~crc;
 
 #ifdef WORDS_BIGENDIAN
 	crc = bswap64(crc);
 #endif
 
 	if (size > 4) {
 		while ((uintptr_t)(buf) & 3) {
 			crc = lzma_crc64_table[0][*buf++ ^ A1(crc)] ^ S8(crc);
 			--size;
 		}
 
 		const uint8_t *const limit = buf + (size & ~(size_t)(3));
 		size &= (size_t)(3);
 
 		while (buf < limit) {
 #ifdef WORDS_BIGENDIAN
 			const uint32_t tmp = (uint32_t)(crc >> 32)
 					^ aligned_read32ne(buf);
 #else
 			const uint32_t tmp = (uint32_t)crc
 					^ aligned_read32ne(buf);
 #endif
 			buf += 4;
 
 			crc = lzma_crc64_table[3][A(tmp)]
 			    ^ lzma_crc64_table[2][B(tmp)]
 			    ^ S32(crc)
 			    ^ lzma_crc64_table[1][C(tmp)]
 			    ^ lzma_crc64_table[0][D(tmp)];
 		}
 	}
 
 	while (size-- != 0)
 		crc = lzma_crc64_table[0][*buf++ ^ A1(crc)] ^ S8(crc);
 
 #ifdef WORDS_BIGENDIAN
 	crc = bswap64(crc);
 #endif
 
 	return ~crc;
 }
 #endif
 
 #if defined(CRC_GENERIC) && defined(CRC_CLMUL)
 //////////////////////////
 // Function dispatching //
 //////////////////////////
 
 // If both the generic and CLMUL implementations are usable, then the
 // function that is used is selected at runtime. See crc32_fast.c.
 
 typedef uint64_t (*crc64_func_type)(
 		const uint8_t *buf, size_t size, uint64_t crc);
 
 #if defined(HAVE_FUNC_ATTRIBUTE_IFUNC) && defined(__clang__)
 #	pragma GCC diagnostic push
 #	pragma GCC diagnostic ignored "-Wunused-function"
 #endif
 
 static crc64_func_type
 crc64_resolve(void)
 {
-	return lzma_is_clmul_supported() ? &lzma_crc64_clmul : &crc64_generic;
+	return is_clmul_supported() ? &lzma_crc64_clmul : &crc64_generic;
 }
 
 #if defined(HAVE_FUNC_ATTRIBUTE_IFUNC) && defined(__clang__)
 #	pragma GCC diagnostic pop
 #endif
 
 #ifndef HAVE_FUNC_ATTRIBUTE_IFUNC
 
 #ifdef HAVE_FUNC_ATTRIBUTE_CONSTRUCTOR
 #	define CRC64_SET_FUNC_ATTR __attribute__((__constructor__))
 static crc64_func_type crc64_func;
 #else
 #	define CRC64_SET_FUNC_ATTR
 static uint64_t crc64_dispatch(const uint8_t *buf, size_t size, uint64_t crc);
 static crc64_func_type crc64_func = &crc64_dispatch;
 #endif
 
 
 CRC64_SET_FUNC_ATTR
 static void
 crc64_set_func(void)
 {
 	crc64_func = crc64_resolve();
 	return;
 }
 
 
 #ifndef HAVE_FUNC_ATTRIBUTE_CONSTRUCTOR
 static uint64_t
 crc64_dispatch(const uint8_t *buf, size_t size, uint64_t crc)
 {
 	crc64_set_func();
 	return crc64_func(buf, size, crc);
 }
 #endif
 #endif
 #endif
 
 
 #ifdef CRC_USE_IFUNC
 extern LZMA_API(uint64_t)
 lzma_crc64(const uint8_t *buf, size_t size, uint64_t crc)
 		__attribute__((__ifunc__("crc64_resolve")));
 #else
 extern LZMA_API(uint64_t)
 lzma_crc64(const uint8_t *buf, size_t size, uint64_t crc)
 {
 #if defined(CRC_GENERIC) && defined(CRC_CLMUL)
 
 #ifdef CRC_USE_GENERIC_FOR_SMALL_INPUTS
 	if (size <= 16)
 		return crc64_generic(buf, size, crc);
 #endif
 	return crc64_func(buf, size, crc);
 
 #elif defined(CRC_CLMUL)
 	// If CLMUL is used unconditionally without runtime CPU detection
 	// then omitting the generic version and its 8 KiB lookup table
 	// makes the library smaller.
 	//
 	// FIXME: Lookup table isn't currently omitted on 32-bit x86,
 	// see crc64_table.c.
 	return lzma_crc64_clmul(buf, size, crc);
 
 #else
 	return crc64_generic(buf, size, crc);
 #endif
 }
 #endif
diff --git a/src/liblzma/check/crc_clmul.c b/src/liblzma/check/crc_clmul.c
index 7110fd7e..640415e7 100644
--- a/src/liblzma/check/crc_clmul.c
+++ b/src/liblzma/check/crc_clmul.c
@@ -1,419 +1,374 @@
 ///////////////////////////////////////////////////////////////////////////////
 //
 /// \file       crc_clmul.c
 /// \brief      CRC32 and CRC64 implementations using CLMUL instructions.
 ///
 /// lzma_crc32_clmul() and lzma_crc64_clmul() use 32/64-bit x86
 /// SSSE3, SSE4.1, and CLMUL instructions. This is compatible with
 /// Elbrus 2000 (E2K) too.
 ///
 /// They were derived from
 /// https://www.researchgate.net/publication/263424619_Fast_CRC_computation
 /// and the public domain code from https://github.com/rawrunprotected/crc
 /// (URLs were checked on 2023-10-14).
 ///
 /// FIXME: Builds for 32-bit x86 use the assembly .S files by default
 /// unless configured with --disable-assembler. Even then the lookup table
 /// isn't omitted in crc64_table.c since it doesn't know that assembly
 /// code has been disabled.
 //
 //  Authors:    Ilya Kurdyukov
 //              Hans Jansen
 //              Lasse Collin
 //              Jia Tan
 //
 //
 //  This file has been put into the public domain.
 //  You can do whatever you want with this file.
 //
 ///////////////////////////////////////////////////////////////////////////////
 
 #include "crc_common.h"
 #include <immintrin.h>
 
 
 #define MASK_L(in, mask, r) r = _mm_shuffle_epi8(in, mask)
 
 #define MASK_H(in, mask, r) \
 	r = _mm_shuffle_epi8(in, _mm_xor_si128(mask, vsign))
 
 #define MASK_LH(in, mask, low, high) \
 	MASK_L(in, mask, low); \
 	MASK_H(in, mask, high)
 
 
 #if (defined(__GNUC__) || defined(__clang__)) && !defined(__EDG__)
 __attribute__((__target__("ssse3,sse4.1,pclmul")))
 #endif
 #if lzma_has_attribute(__no_sanitize_address__)
 __attribute__((__no_sanitize_address__))
 #endif
 static crc_always_inline void
 crc_simd_body(const uint8_t *buf, const size_t size, __m128i *v0, __m128i *v1,
 		const __m128i vfold16, const __m128i initial_crc)
 {
 	// Create a vector with 8-bit values 0 to 15. This is used to
 	// construct control masks for _mm_blendv_epi8 and _mm_shuffle_epi8.
 	const __m128i vramp = _mm_setr_epi32(
 			0x03020100, 0x07060504, 0x0b0a0908, 0x0f0e0d0c);
 
 	// This is used to inverse the control mask of _mm_shuffle_epi8
 	// so that bytes that wouldn't be picked with the original mask
 	// will be picked and vice versa.
 	const __m128i vsign = _mm_set1_epi8(-0x80);
 
 	// Memory addresses A to D and the distances between them:
 	//
 	//     A           B     C         D
 	//     [skip_start][size][skip_end]
 	//     [     size2      ]
 	//
 	// A and D are 16-byte aligned. B and C are 1-byte aligned.
 	// skip_start and skip_end are 0-15 bytes. size is at least 1 byte.
 	//
 	// A = aligned_buf will initially point to this address.
 	// B = The address pointed by the caller-supplied buf.
 	// C = buf + size == aligned_buf + size2
 	// D = buf + size + skip_end == aligned_buf + size2 + skip_end
 	const size_t skip_start = (size_t)((uintptr_t)buf & 15);
 	const size_t skip_end = (size_t)((0U - (uintptr_t)(buf + size)) & 15);
 	const __m128i *aligned_buf = (const __m128i *)(
 			(uintptr_t)buf & ~(uintptr_t)15);
 
 	// If size2 <= 16 then the whole input fits into a single 16-byte
 	// vector. If size2 > 16 then at least two 16-byte vectors must
 	// be processed. If size2 > 16 && size <= 16 then there is only
 	// one 16-byte vector's worth of input but it is unaligned in memory.
 	//
 	// NOTE: There is no integer overflow here if the arguments
 	// are valid. If this overflowed, buf + size would too.
 	const size_t size2 = skip_start + size;
 
 	// Masks to be used with _mm_blendv_epi8 and _mm_shuffle_epi8:
 	// The first skip_start or skip_end bytes in the vectors will have
 	// the high bit (0x80) set. _mm_blendv_epi8 and _mm_shuffle_epi8
 	// will produce zeros for these positions. (Bitwise-xor of these
 	// masks with vsign will produce the opposite behavior.)
 	const __m128i mask_start
 			= _mm_sub_epi8(vramp, _mm_set1_epi8((char)skip_start));
 	const __m128i mask_end
 			= _mm_sub_epi8(vramp, _mm_set1_epi8((char)skip_end));
 
 	// Get the first 1-16 bytes into data0. If loading less than 16
 	// bytes, the bytes are loaded to the high bits of the vector and
 	// the least significant positions are filled with zeros.
 	const __m128i data0 = _mm_blendv_epi8(_mm_load_si128(aligned_buf),
 			_mm_setzero_si128(), mask_start);
 	aligned_buf++;
 
 	__m128i v2, v3;
 
 #ifndef CRC_USE_GENERIC_FOR_SMALL_INPUTS
 	if (size <= 16) {
 		// Right-shift initial_crc by 1-16 bytes based on "size"
 		// and store the result in v1 (high bytes) and v0 (low bytes).
 		//
 		// NOTE: The highest 8 bytes of initial_crc are zeros so
 		// v1 will be filled with zeros if size >= 8. The highest
 		// 8 bytes of v1 will always become zeros.
 		//
 		// [      v1      ][      v0      ]
 		//  [ initial_crc  ]                  size == 1
 		//   [ initial_crc  ]                 size == 2
 		//                [ initial_crc  ]    size == 15
 		//                 [ initial_crc  ]   size == 16 (all in v0)
 		const __m128i mask_low = _mm_add_epi8(
 				vramp, _mm_set1_epi8((char)(size - 16)));
 		MASK_LH(initial_crc, mask_low, *v0, *v1);
 
 		if (size2 <= 16) {
 			// There are 1-16 bytes of input and it is all
 			// in data0. Copy the input bytes to v3. If there
 			// are fewer than 16 bytes, the low bytes in v3
 			// will be filled with zeros. That is, the input
 			// bytes are stored to the same position as
 			// (part of) initial_crc is in v0.
 			MASK_L(data0, mask_end, v3);
 		} else {
 			// There are 2-16 bytes of input but not all bytes
 			// are in data0.
 			const __m128i data1 = _mm_load_si128(aligned_buf);
 
 			// Collect the 2-16 input bytes from data0 and data1
 			// to v2 and v3, and bitwise-xor them with the
 			// low bits of initial_crc in v0. Note that the
 			// the second xor is below this else-block as it
 			// is shared with the other branch.
 			MASK_H(data0, mask_end, v2);
 			MASK_L(data1, mask_end, v3);
 			*v0 = _mm_xor_si128(*v0, v2);
 		}
 
 		*v0 = _mm_xor_si128(*v0, v3);
 		*v1 = _mm_alignr_epi8(*v1, *v0, 8);
 	} else
 #endif
 	{
 		// There is more than 16 bytes of input.
 		const __m128i data1 = _mm_load_si128(aligned_buf);
 		const __m128i *end = (const __m128i*)(
 				(const char *)aligned_buf - 16 + size2);
 		aligned_buf++;
 
 		MASK_LH(initial_crc, mask_start, *v0, *v1);
 		*v0 = _mm_xor_si128(*v0, data0);
 		*v1 = _mm_xor_si128(*v1, data1);
 
 		while (aligned_buf < end) {
 			*v1 = _mm_xor_si128(*v1, _mm_clmulepi64_si128(
 					*v0, vfold16, 0x00));
 			*v0 = _mm_xor_si128(*v1, _mm_clmulepi64_si128(
 					*v0, vfold16, 0x11));
 			*v1 = _mm_load_si128(aligned_buf++);
 		}
 
 		if (aligned_buf != end) {
 			MASK_H(*v0, mask_end, v2);
 			MASK_L(*v0, mask_end, *v0);
 			MASK_L(*v1, mask_end, v3);
 			*v1 = _mm_or_si128(v2, v3);
 		}
 
 		*v1 = _mm_xor_si128(*v1, _mm_clmulepi64_si128(
 				*v0, vfold16, 0x00));
 		*v0 = _mm_xor_si128(*v1, _mm_clmulepi64_si128(
 				*v0, vfold16, 0x11));
 		*v1 = _mm_srli_si128(*v0, 8);
 	}
 }
 
 
 /////////////////////
 // x86 CLMUL CRC32 //
 /////////////////////
 
 /*
 // These functions were used to generate the constants
 // at the top of lzma_crc32_clmul().
 static uint64_t
 calc_lo(uint64_t p, uint64_t a, int n)
 {
 	uint64_t b = 0; int i;
 	for (i = 0; i < n; i++) {
 		b = b >> 1 | (a & 1) << (n - 1);
 		a = (a >> 1) ^ ((0 - (a & 1)) & p);
 	}
 	return b;
 }
 
 // same as ~crc(&a, sizeof(a), ~0)
 static uint64_t
 calc_hi(uint64_t p, uint64_t a, int n)
 {
 	int i;
 	for (i = 0; i < n; i++)
 		a = (a >> 1) ^ ((0 - (a & 1)) & p);
 	return a;
 }
 */
 
 #ifdef HAVE_CHECK_CRC32
 
 // EDG-based compilers (Intel's classic compiler and compiler for E2K) can
 // define __GNUC__ but the attribute must not be used with them.
 // The new Clang-based ICX needs the attribute.
 //
 // NOTE: Build systems check for this too, keep them in sync with this.
 #if (defined(__GNUC__) || defined(__clang__)) && !defined(__EDG__)
 __attribute__((__target__("ssse3,sse4.1,pclmul")))
 #endif
 #if lzma_has_attribute(__no_sanitize_address__)
 __attribute__((__no_sanitize_address__))
 #endif
 extern uint32_t
 lzma_crc32_clmul(const uint8_t *buf, size_t size, uint32_t crc)
 {
 #ifndef CRC_USE_GENERIC_FOR_SMALL_INPUTS
 	// The code assumes that there is at least one byte of input.
 	if (size == 0)
 		return crc;
 #endif
 
 	// uint32_t poly = 0xedb88320;
 	const int64_t p = 0x1db710640; // p << 1
 	const int64_t mu = 0x1f7011641; // calc_lo(p, p, 32) << 1 | 1
 	const int64_t k5 = 0x163cd6124; // calc_hi(p, p, 32) << 1
 	const int64_t k4 = 0x0ccaa009e; // calc_hi(p, p, 64) << 1
 	const int64_t k3 = 0x1751997d0; // calc_hi(p, p, 128) << 1
 
 	const __m128i vfold4 = _mm_set_epi64x(mu, p);
 	const __m128i vfold8 = _mm_set_epi64x(0, k5);
 	const __m128i vfold16 = _mm_set_epi64x(k4, k3);
 
 	__m128i v0, v1, v2;
 
 	crc_simd_body(buf,  size, &v0, &v1, vfold16,
 			_mm_cvtsi32_si128((int32_t)~crc));
 
 	v1 = _mm_xor_si128(
 			_mm_clmulepi64_si128(v0, vfold16, 0x10), v1); // xxx0
 	v2 = _mm_shuffle_epi32(v1, 0xe7); // 0xx0
 	v0 = _mm_slli_epi64(v1, 32);  // [0]
 	v0 = _mm_clmulepi64_si128(v0, vfold8, 0x00);
 	v0 = _mm_xor_si128(v0, v2);   // [1] [2]
 	v2 = _mm_clmulepi64_si128(v0, vfold4, 0x10);
 	v2 = _mm_clmulepi64_si128(v2, vfold4, 0x00);
 	v0 = _mm_xor_si128(v0, v2);   // [2]
 	return ~(uint32_t)_mm_extract_epi32(v0, 2);
 }
 #endif // HAVE_CHECK_CRC32
 
 
 /////////////////////
 // x86 CLMUL CRC64 //
 /////////////////////
 
 /*
 // These functions were used to generate the constants
 // at the top of lzma_crc64_clmul().
 static uint64_t
 calc_lo(uint64_t poly)
 {
 	uint64_t a = poly;
 	uint64_t b = 0;
 
 	for (unsigned i = 0; i < 64; ++i) {
 		b = (b >> 1) | (a << 63);
 		a = (a >> 1) ^ (a & 1 ? poly : 0);
 	}
 
 	return b;
 }
 
 static uint64_t
 calc_hi(uint64_t poly, uint64_t a)
 {
 	for (unsigned i = 0; i < 64; ++i)
 		a = (a >> 1) ^ (a & 1 ? poly : 0);
 
 	return a;
 }
 */
 
 #ifdef HAVE_CHECK_CRC64
 
 // MSVC (VS2015 - VS2022) produces bad 32-bit x86 code from the CLMUL CRC
 // code when optimizations are enabled (release build). According to the bug
 // report, the ebx register is corrupted and the calculated result is wrong.
 // Trying to workaround the problem with "__asm mov ebx, ebx" didn't help.
 // The following pragma works and performance is still good. x86-64 builds
 // and CRC32 CLMUL aren't affected by this problem. The problem does not
 // happen in crc_simd_body() either (which is shared with CRC32 CLMUL anyway).
 //
 // NOTE: Another pragma after lzma_crc64_clmul() restores the optimizations.
 // If the #if condition here is updated, the other one must be updated too.
 #if defined(_MSC_VER) && !defined(__INTEL_COMPILER) && !defined(__clang__) \
 		&& defined(_M_IX86)
 #	pragma optimize("g", off)
 #endif
 
 #if (defined(__GNUC__) || defined(__clang__)) && !defined(__EDG__)
 __attribute__((__target__("ssse3,sse4.1,pclmul")))
 #endif
 #if lzma_has_attribute(__no_sanitize_address__)
 __attribute__((__no_sanitize_address__))
 #endif
 extern uint64_t
 lzma_crc64_clmul(const uint8_t *buf, size_t size, uint64_t crc)
 {
 #ifndef CRC_USE_GENERIC_FOR_SMALL_INPUTS
 	// The code assumes that there is at least one byte of input.
 	if (size == 0)
 		return crc;
 #endif
 
 	// const uint64_t poly = 0xc96c5795d7870f42; // CRC polynomial
 	const uint64_t p  = 0x92d8af2baf0e1e85; // (poly << 1) | 1
 	const uint64_t mu = 0x9c3e466c172963d5; // (calc_lo(poly) << 1) | 1
 	const uint64_t k2 = 0xdabe95afc7875f40; // calc_hi(poly, 1)
 	const uint64_t k1 = 0xe05dd497ca393ae4; // calc_hi(poly, k2)
 
 	const __m128i vfold8 = _mm_set_epi64x((int64_t)p, (int64_t)mu);
 	const __m128i vfold16 = _mm_set_epi64x((int64_t)k2, (int64_t)k1);
 
 	__m128i v0, v1, v2;
 
 #if defined(__i386__) || defined(_M_IX86)
 	crc_simd_body(buf,  size, &v0, &v1, vfold16,
 			_mm_set_epi64x(0, (int64_t)~crc));
 #else
 	// GCC and Clang would produce good code with _mm_set_epi64x
 	// but MSVC needs _mm_cvtsi64_si128 on x86-64.
 	crc_simd_body(buf,  size, &v0, &v1, vfold16,
 			_mm_cvtsi64_si128((int64_t)~crc));
 #endif
 
 	v1 = _mm_xor_si128(_mm_clmulepi64_si128(v0, vfold16, 0x10), v1);
 	v0 = _mm_clmulepi64_si128(v1, vfold8, 0x00);
 	v2 = _mm_clmulepi64_si128(v0, vfold8, 0x10);
 	v0 = _mm_xor_si128(_mm_xor_si128(v1, _mm_slli_si128(v0, 8)), v2);
 
 #if defined(__i386__) || defined(_M_IX86)
 	return ~(((uint64_t)(uint32_t)_mm_extract_epi32(v0, 3) << 32) |
 			(uint64_t)(uint32_t)_mm_extract_epi32(v0, 2));
 #else
 	return ~(uint64_t)_mm_extract_epi64(v0, 1);
 #endif
 }
 #endif // HAVE_CHECK_CRC64
 
 
 #if defined(_MSC_VER) && !defined(__INTEL_COMPILER) && !defined(__clang__) \
 		&& defined(_M_IX86)
 #	pragma optimize("", on)
 #endif
-
-
-////////////////////////
-// Detect CPU support //
-////////////////////////
-
-extern bool
-lzma_is_clmul_supported(void)
-{
-	int success = 1;
-	uint32_t r[4]; // eax, ebx, ecx, edx
-
-#if defined(_MSC_VER)
-	// This needs <intrin.h> with MSVC. ICC has it as a built-in
-	// on all platforms.
-	__cpuid(r, 1);
-#elif defined(HAVE_CPUID_H)
-	// Compared to just using __asm__ to run CPUID, this also checks
-	// that CPUID is supported and saves and restores ebx as that is
-	// needed with GCC < 5 with position-independent code (PIC).
-	success = __get_cpuid(1, &r[0], &r[1], &r[2], &r[3]);
-#else
-	// Just a fallback that shouldn't be needed.
-	__asm__("cpuid\n\t"
-			: "=a"(r[0]), "=b"(r[1]), "=c"(r[2]), "=d"(r[3])
-			: "a"(1), "c"(0));
-#endif
-
-	// Returns true if these are supported:
-	// CLMUL (bit 1 in ecx)
-	// SSSE3 (bit 9 in ecx)
-	// SSE4.1 (bit 19 in ecx)
-	const uint32_t ecx_mask = (1 << 1) | (1 << 9) | (1 << 19);
-	return success && (r[2] & ecx_mask) == ecx_mask;
-
-	// Alternative methods that weren't used:
-	//   - ICC's _may_i_use_cpu_feature: the other methods should work too.
-	//   - GCC >= 6 / Clang / ICX __builtin_cpu_supports("pclmul")
-	//
-	// CPUID decding is needed with MSVC anyway and older GCC. This keeps
-	// the feature checks in the build system simpler too. The nice thing
-	// about __builtin_cpu_supports would be that it generates very short
-	// code as is it only reads a variable set at startup but a few bytes
-	// doesn't matter here.
-}
diff --git a/src/liblzma/check/crc_common.h b/src/liblzma/check/crc_common.h
index 51ddd9d5..1783b5e7 100644
--- a/src/liblzma/check/crc_common.h
+++ b/src/liblzma/check/crc_common.h
@@ -1,116 +1,162 @@
 ///////////////////////////////////////////////////////////////////////////////
 //
 /// \file       crc_common.h
 /// \brief      Some functions and macros for CRC32 and CRC64
 //
 //  Authors:    Lasse Collin
 //              Ilya Kurdyukov
 //              Hans Jansen
 //              Jia Tan
 //
 //  This file has been put into the public domain.
 //  You can do whatever you want with this file.
 //
 ///////////////////////////////////////////////////////////////////////////////
 
 #ifndef LZMA_CRC_COMMON_H
 #define LZMA_CRC_COMMON_H
 
 #include "common.h"
 
 
 #ifdef WORDS_BIGENDIAN
 #	define A(x) ((x) >> 24)
 #	define B(x) (((x) >> 16) & 0xFF)
 #	define C(x) (((x) >> 8) & 0xFF)
 #	define D(x) ((x) & 0xFF)
 
 #	define S8(x) ((x) << 8)
 #	define S32(x) ((x) << 32)
 
 #else
 #	define A(x) ((x) & 0xFF)
 #	define B(x) (((x) >> 8) & 0xFF)
 #	define C(x) (((x) >> 16) & 0xFF)
 #	define D(x) ((x) >> 24)
 
 #	define S8(x) ((x) >> 8)
 #	define S32(x) ((x) >> 32)
 #endif
 
 
 // The inline keyword is only a suggestion to the compiler to substitute the
 // body of the function into the places where it is called. If a function
 // is large and called multiple times then compiler may choose to ignore the
 // inline suggestion at a sometimes high performance cost.
 //
 // MSVC's __forceinline is a keyword that should be used in place of inline.
 // If both __forceinline and inline are used, MSVC will issue a warning.
 // Since MSVC's keyword is a replacement keyword, the lzma_always_inline
 // macro must also contain the inline keyword when its not used in MSVC.
 #ifdef _MSC_VER
 #	define crc_always_inline __forceinline
 #else
 #	define crc_always_inline __attribute__((__always_inline__)) inline
 #endif
 
 #undef CRC_GENERIC
 #undef CRC_CLMUL
 #undef CRC_USE_IFUNC
 #undef CRC_USE_GENERIC_FOR_SMALL_INPUTS
 
 // If CLMUL cannot be used then only the generic slice-by-four is built.
 #if !defined(HAVE_USABLE_CLMUL)
 #	define CRC_GENERIC 1
 
 // If CLMUL is allowed unconditionally in the compiler options then the
 // generic version can be omitted. Note that this doesn't work with MSVC
 // as I don't know how to detect the features here.
 //
 // NOTE: Keep this this in sync with crc32_table.c.
 #elif (defined(__SSSE3__) && defined(__SSE4_1__) && defined(__PCLMUL__)) \
 		|| (defined(__e2k__) && __iset__ >= 6)
 #	define CRC_CLMUL 1
 
 // Otherwise build both and detect at runtime which version to use.
 #else
 #	define CRC_GENERIC 1
 #	define CRC_CLMUL 1
 
 #	ifdef HAVE_FUNC_ATTRIBUTE_IFUNC
 #		define CRC_USE_IFUNC 1
 #	endif
 
 /*
 	// The generic code is much faster with 1-8-byte inputs and has
 	// similar performance up to 16 bytes  at least in microbenchmarks
 	// (it depends on input buffer alignment too). If both versions are
 	// built, this #define will use the generic version for inputs up to
 	// 16 bytes and CLMUL for bigger inputs. It saves a little in code
 	// size since the special cases for 0-16-byte inputs will be omitted
 	// from the CLMUL code.
 #	ifndef CRC_USE_IFUNC
 #		define CRC_USE_GENERIC_FOR_SMALL_INPUTS 1
 #	endif
 */
 
 #	if defined(_MSC_VER)
 #		include <intrin.h>
 #	elif defined(HAVE_CPUID_H)
 #		include <cpuid.h>
 #	endif
+
+// is_clmul_supported() must be inlined in this header file because the
+// ifunc resolver function may not support calling a function in another
+// translation unit. Depending on compiler-toolchain and flags, a call to
+// a function defined in another translation unit could result in a
+// reference to the PLT, which is unsafe to do in an ifunc resolver. The
+// ifunc resolver runs very early when loading a shared library, so the PLT
+// entries may not be setup at that time. Inlining this function duplicates
+// the function body in crc32_resolve() and crc64_resolve(), but this is
+// acceptable because the function results in very few instructions.
+static inline bool
+is_clmul_supported(void)
+{
+	int success = 1;
+	uint32_t r[4]; // eax, ebx, ecx, edx
+
+#if defined(_MSC_VER)
+	// This needs <intrin.h> with MSVC. ICC has it as a built-in
+	// on all platforms.
+	__cpuid(r, 1);
+#elif defined(HAVE_CPUID_H)
+	// Compared to just using __asm__ to run CPUID, this also checks
+	// that CPUID is supported and saves and restores ebx as that is
+	// needed with GCC < 5 with position-independent code (PIC).
+	success = __get_cpuid(1, &r[0], &r[1], &r[2], &r[3]);
+#else
+	// Just a fallback that shouldn't be needed.
+	__asm__("cpuid\n\t"
+			: "=a"(r[0]), "=b"(r[1]), "=c"(r[2]), "=d"(r[3])
+			: "a"(1), "c"(0));
 #endif
 
-/// Detect at runtime if the CPU supports the x86 CLMUL instruction when
-/// both the generic and CLMUL implementations are built.
-extern bool lzma_is_clmul_supported(void);
+	// Returns true if these are supported:
+	// CLMUL (bit 1 in ecx)
+	// SSSE3 (bit 9 in ecx)
+	// SSE4.1 (bit 19 in ecx)
+	const uint32_t ecx_mask = (1 << 1) | (1 << 9) | (1 << 19);
+	return success && (r[2] & ecx_mask) == ecx_mask;
+
+	// Alternative methods that weren't used:
+	//   - ICC's _may_i_use_cpu_feature: the other methods should work too.
+	//   - GCC >= 6 / Clang / ICX __builtin_cpu_supports("pclmul")
+	//
+	// CPUID decding is needed with MSVC anyway and older GCC. This keeps
+	// the feature checks in the build system simpler too. The nice thing
+	// about __builtin_cpu_supports would be that it generates very short
+	// code as is it only reads a variable set at startup but a few bytes
+	// doesn't matter here.
+}
+
+#endif
 
 /// CRC32 implemented with the x86 CLMUL instruction.
 extern uint32_t lzma_crc32_clmul(const uint8_t *buf, size_t size,
 		uint32_t crc);
 
 /// CRC64 implemented with the x86 CLMUL instruction.
 extern uint64_t lzma_crc64_clmul(const uint8_t *buf, size_t size,
 		uint64_t crc);
 
 #endif